{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac0b3e0-f90c-4eda-aa10-98d1808fafdc",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ce990d-373c-445a-bd87-ebf5b6be7337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 26 12:02:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   39C    P0              N/A /  55W |     14MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1196      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      1863      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435178fd-79d2-4ac1-9959-4c85b1222c90",
   "metadata": {},
   "source": [
    "### 计算设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680abd59-7522-448b-b68c-c7442aff4091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " <torch.cuda.device at 0x7fa352fc6c50>,\n",
       " <torch.cuda.device at 0x7fa352fc6650>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'), torch.cuda.device('cuda'), torch.cuda.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78f9b7-c01d-4db0-8c3d-f2539d8c629d",
   "metadata": {},
   "source": [
    "### 查询可用gpu的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b35d69-bcfe-4fb5-a497-596c97bb05d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69733769-34bf-4ce5-afcd-398a59254779",
   "metadata": {},
   "source": [
    "### 这两个函数允许我们在请求的GPU不存在的情况下运行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4278008a-feb1-4f52-907b-4cc56e533d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " [device(type='cuda', index=0)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i = 0):\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()。\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。\"\"\"\n",
    "    devices = [\n",
    "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd364fd4-bd77-446a-9f69-3d0c96f1fa61",
   "metadata": {},
   "source": [
    "### 查询张量所在设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd976f4-07d3-43e9-bf32-1446138b78a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c391b7-5cf5-4ee4-b14e-4dea990120c8",
   "metadata": {},
   "source": [
    "### 存储在GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1764eb-b655-4bce-a1d4-17969dd93ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device = try_gpu())\n",
    "X.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3664c7-c560-4f8d-8ab9-6fe4b9ef1ab6",
   "metadata": {},
   "source": [
    "### 第二个GPU上创建一个随机张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5513d358-27e2-4a3f-892c-f85527ddc501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand(2, 3, device = try_gpu(1))  # 因为我们只有一张GPU，所以只能将其存储在CPU上\n",
    "Y.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc95afc-212d-42ee-b3e5-f66ea67a7c5e",
   "metadata": {},
   "source": [
    "### 要计算$X + Y$，我们需要决定在哪里执行这个操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05e94d4-1661-4d52-b6a3-f1faa7db1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5665, 0.7005, 0.4085],\n",
      "        [0.3471, 0.0925, 0.4717]])\n",
      "tensor([[0.5665, 0.7005, 0.4085],\n",
      "        [0.3471, 0.0925, 0.4717]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 在GPU上进行计算，最好确保两个变量都在同一张GPU上，因为在GPU与CPU之间进行频繁的数据传输，会导致性能问题\n",
    "Z = Y.cuda(0)\n",
    "print(Y)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9209b25-098d-4228-8372-51d4b884c52a",
   "metadata": {},
   "source": [
    "### 现在数据在同一张GPU上（$Z$和$X$都在），我们可以将它们相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcc360b0-76a8-4e9a-8177-52f5357958cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5665, 1.7005, 1.4085],\n",
       "        [1.3471, 1.0925, 1.4717]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c76bd64-000e-43e7-bead-7f4be842396f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.cuda(0) is Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322fd81-3f36-41d9-9ea9-29bb6c68223b",
   "metadata": {},
   "source": [
    "### 神经网络与GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c0e2b6-e5e7-4c5e-9c41-ea3876097db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4078],\n",
       "        [0.4078]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))\n",
    "net = net.to(device = try_gpu())\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b707980-a0fa-4823-a761-7d1fece93052",
   "metadata": {},
   "source": [
    "### 确认模型参数存储在同一个GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20b08420-89af-48a2-8b44-726438b4d4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
